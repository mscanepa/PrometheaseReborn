#!/usr/bin/env python3
"""
TheModernPromethease - Aplicaci√≥n Web de An√°lisis Gen√©tico

Esta aplicaci√≥n web permite a los usuarios subir sus datos gen√©ticos y ejecutar
el pipeline completo de an√°lisis gen√©tico de manera sencilla e interactiva.

La aplicaci√≥n:
1. Permite subir archivos de datos gen√©ticos (incluyendo conversi√≥n de MyHeritage)
2. Ejecuta autom√°ticamente el pipeline de an√°lisis
3. Muestra los resultados de manera clara y amigable
"""

import streamlit as st
import os
import subprocess
import time
from pathlib import Path
import shutil
import pandas as pd
import tempfile
import re
import numpy as np
import pyarrow as pa
import pyarrow.parquet as pq
from datetime import datetime
import uuid
import logging
from src.genomic_database_manager import GenomicDatabaseManager
from src.database_optimizer import DatabaseOptimizer
from typing import Tuple
import json

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# =============================================================================
# Configuraci√≥n Inicial
# =============================================================================

# Configurar el t√≠tulo y la descripci√≥n de la p√°gina
st.set_page_config(
    page_title="TheModernPromethease",
    page_icon="üß¨",
    layout="centered"
)

# T√≠tulo principal
st.title("üß¨ TheModernPromethease")
st.markdown("""
    ### An√°lisis Gen√©tico Personalizado
    
    Sube tus datos gen√©ticos para obtener un an√°lisis completo de tu predisposici√≥n gen√©tica
    a diferentes condiciones de salud.
""")

# =============================================================================
# Funciones Auxiliares
# =============================================================================

def generar_id_unico():
    """Genera un ID √∫nico basado en timestamp y UUID."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    unique_id = str(uuid.uuid4())[:8]
    return f"{timestamp}_{unique_id}"

def verificar_estructura_directorios():
    """Verifica y crea la estructura de directorios necesaria."""
    directorios = [
        'data/raw', 
        'data/processed', 
        'data/myheritage',
        'reports'
    ]
    for directorio in directorios:
        Path(directorio).mkdir(parents=True, exist_ok=True)
        logger.info(f"Verified directory exists: {directorio}")

def validate_myheritage_data(df: pd.DataFrame) -> bool:
    """Validate MyHeritage data format and content."""
    try:
        # Check required columns
        required_columns = ['RSID', 'CHROMOSOME', 'POSITION', 'RESULT']
        if not all(col in df.columns for col in required_columns):
            st.error(f"‚ùå Error: Columnas faltantes. Se encontraron: {df.columns.tolist()}")
            st.error(f"‚ùå Se esperaban las columnas: {', '.join(required_columns)}")
            return False
        
        # Validate chromosome values
        valid_chromosomes = set(str(i) for i in range(1, 23)) | {'X', 'Y', 'MT'}
        invalid_chromosomes = set(df['CHROMOSOME'].astype(str)) - valid_chromosomes
        if invalid_chromosomes:
            st.error(f"‚ùå Error: Valores inv√°lidos en CHROMOSOME: {invalid_chromosomes}")
            st.error("Los valores v√°lidos son n√∫meros del 1 al 22, X, Y o MT")
            return False
        
        # Validate position values
        if not pd.api.types.is_numeric_dtype(df['POSITION']):
            st.error("‚ùå Error: La columna POSITION debe contener valores num√©ricos")
            return False
        
        # Validate RSID format
        if not df['RSID'].str.startswith('rs').all():
            st.error("‚ùå Error: Todos los valores de RSID deben comenzar con 'rs'")
            return False
        
        # Validate genotype format
        valid_genotypes = {'AA', 'AC', 'AG', 'AT', 'CA', 'CC', 'CG', 'CT', 
                          'GA', 'GC', 'GG', 'GT', 'TA', 'TC', 'TG', 'TT', 
                          '--', 'II', 'DD', 'DI', 'ID'}
        invalid_genotypes = set(df['RESULT'].astype(str)) - valid_genotypes
        if invalid_genotypes:
            st.error(f"‚ùå Error: Valores de genotipo inv√°lidos encontrados: {invalid_genotypes}")
            st.error("Los valores v√°lidos son combinaciones de A, C, G, T o los valores especiales: --, II, DD, DI, ID")
            return False
        
        return True
    except Exception as e:
        st.error(f"‚ùå Error durante la validaci√≥n: {str(e)}")
        return False

def convert_myheritage(df: pd.DataFrame) -> Tuple[pd.DataFrame, str]:
    """Convert MyHeritage data to required format."""
    try:
        # Generate unique session ID
        session_id = generar_id_unico()
        logger.info(f"Generated session ID: {session_id}")
        
        # Ensure directories exist
        os.makedirs("data/raw", exist_ok=True)
        os.makedirs("data/myheritage", exist_ok=True)
        logger.info("Verified directory structure")
        
        # Convert chromosome values to string and standardize format
        df['CHROMOSOME'] = df['CHROMOSOME'].astype(str).str.upper()
        
        # Ensure position is numeric
        df['POSITION'] = pd.to_numeric(df['POSITION'], errors='coerce')
        
        # Create the output DataFrame with required columns
        converted_df = pd.DataFrame({
            'rsid': df['RSID'],
            'chromosome': df['CHROMOSOME'],
            'position': df['POSITION'],
            'genotype': df['RESULT']
        })
        
        # Remove any rows with missing values
        converted_df = converted_df.dropna()
        logger.info(f"Converted data: {len(converted_df)} rows")
        
        # Save the converted data in Parquet format
        output_path = f"data/raw/usuario_{session_id}.parquet"
        logger.info(f"Guardando archivo Parquet en: {output_path}")
        converted_df.to_parquet(output_path, index=False)
        
        # Verify Parquet file was created
        if not os.path.exists(output_path):
            raise FileNotFoundError(f"No se pudo crear el archivo Parquet en {output_path}")
        logger.info(f"Parquet file created successfully: {output_path}")
        
        # Save a copy in JSON format for MyHeritage specific processing
        myheritage_data = {
            'variants': converted_df.to_dict('records'),
            'session_id': session_id,
            'timestamp': datetime.now().isoformat()
        }
        myheritage_path = os.path.join("data", "myheritage", f"myheritage_{session_id}.json")
        logger.info(f"Guardando archivo JSON en: {myheritage_path}")
        
        try:
            with open(myheritage_path, 'w') as f:
                json.dump(myheritage_data, f, indent=2)
            logger.info(f"JSON data written to file: {myheritage_path}")
        except Exception as e:
            logger.error(f"Error writing JSON file: {str(e)}")
            raise
            
        # Verify JSON file was created
        if not os.path.exists(myheritage_path):
            raise FileNotFoundError(f"No se pudo crear el archivo JSON en {myheritage_path}")
        logger.info(f"JSON file created successfully: {myheritage_path}")
            
        st.success(f"‚úÖ Datos convertidos y guardados exitosamente")
        st.info(f"üìÅ Archivo Parquet: {output_path}")
        st.info(f"üìÅ Archivo JSON: {myheritage_path}")
        st.info(f"ID de sesi√≥n: {session_id}")
        
        return converted_df, session_id
        
    except Exception as e:
        logger.error(f"‚ùå Error al convertir los datos: {str(e)}")
        st.error(f"‚ùå Error al convertir los datos: {str(e)}")
        raise

def validar_archivo(archivo):
    """Valida el formato del archivo de datos gen√©ticos."""
    try:
        # Leer las primeras l√≠neas del archivo
        contenido = archivo.getvalue().decode('utf-8').split('\n')
        if len(contenido) < 2:
            return False, "El archivo est√° vac√≠o o no tiene el formato correcto"
        
        # Verificar encabezados
        encabezados = contenido[0].strip().split('\t')
        columnas_requeridas = ['rsid', 'chromosome', 'position', 'genotype']
        
        if not all(col in encabezados for col in columnas_requeridas):
            return False, "El archivo no contiene todas las columnas requeridas (rsid, chromosome, position, genotype)"
        
        return True, "Archivo v√°lido"
    except Exception as e:
        return False, f"Error al validar el archivo: {str(e)}"

def ejecutar_pipeline(df_convertido, gwas_data, clinvar_data, dbsnp_data):
    """Ejecuta el pipeline de an√°lisis gen√©tico."""
    try:
        # Configurar indicadores de progreso
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Verificar estructura b√°sica
        status_text.text("üîÑ Verificando estructura del pipeline...")
        if not os.access('run_pipeline.sh', os.X_OK):
            st.warning("‚ö†Ô∏è El script run_pipeline.sh no es ejecutable. Intentando hacerlo ejecutable...")
            os.chmod('run_pipeline.sh', 0o755)
        
        # Verificar archivos y permisos
        status_text.text("üîÑ Verificando archivos y permisos...")
        archivo_datos = 'data/raw/usuario_adaptado.txt'
        if not os.path.exists(archivo_datos):
            st.error(f"‚ùå Error: No se encontr√≥ el archivo de datos en {archivo_datos}")
            return False
        
        # Crear directorios necesarios
        directorios = ['data/processed', 'reports']
        for directorio in directorios:
            if not os.path.exists(directorio):
                os.makedirs(directorio)
            if not os.access(directorio, os.W_OK):
                st.error(f"‚ùå Error: No hay permisos de escritura en el directorio {directorio}")
                return False
        
        # Ejecutar pipeline con logging detallado
        status_text.text("üîÑ Iniciando pipeline de an√°lisis (esto puede tomar varios minutos)...")
        
        with tempfile.NamedTemporaryFile(mode='w+', delete=False) as log_file:
            # Configurar variables de entorno para el pipeline
            env = {
                **os.environ,
                'LOG_FILE': log_file.name,
                'SHOW_PROGRESS': 'true',  # Indicar al pipeline que muestre progreso
                'GWAS_DATA': gwas_data,
                'CLINVAR_DATA': clinvar_data,
                'DBSNP_DATA': dbsnp_data
            }
            
            # Ejecutar pipeline en segundo plano para no bloquear la interfaz
            proceso = subprocess.Popen(
                ['./run_pipeline.sh'],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                env=env
            )
            
            # Monitorear progreso
            while True:
                # Leer log para actualizar progreso
                log_file.seek(0)
                log_content = log_file.read()
                
                # Actualizar interfaz
                if "Iniciando extracci√≥n de datos" in log_content:
                    progress_bar.progress(0.2)
                elif "Calculando PRS" in log_content:
                    progress_bar.progress(0.4)
                elif "Generando reporte" in log_content:
                    progress_bar.progress(0.6)
                elif "Generando interpretaci√≥n con IA" in log_content:
                    progress_bar.progress(0.8)
                
                # Verificar si el proceso termin√≥
                if proceso.poll() is not None:
                    break
                
                # Esperar un momento antes de la siguiente actualizaci√≥n
                time.sleep(1)
            
            # Obtener resultados finales
            stdout, stderr = proceso.communicate()
            
            if proceso.returncode != 0:
                st.error("‚ùå Error en el pipeline:")
                st.error(f"C√≥digo de salida: {proceso.returncode}")
                st.error("Salida est√°ndar:")
                st.text(stdout)
                st.error("Error est√°ndar:")
                st.text(stderr)
                st.error("Log del pipeline:")
                st.text(log_content)
                return False
            
            # Mostrar log de √©xito
            progress_bar.progress(1.0)
            status_text.text("‚úÖ Pipeline ejecutado exitosamente")
            st.info("Log del pipeline:")
            st.text(log_content)
        
        return True
        
    except Exception as e:
        st.error(f"‚ùå Error inesperado: {str(e)}")
        st.error("Por favor, verifica los logs para m√°s detalles")
        return False

def leer_resultados():
    """Lee y retorna los resultados del an√°lisis."""
    try:
        with open('reports/prs_result.txt', 'r') as f:
            prs_resultado = f.read()
        with open('reports/prs_interpretation.txt', 'r') as f:
            interpretacion = f.read()
        return prs_resultado, interpretacion
    except Exception as e:
        st.error(f"Error al leer los resultados: {str(e)}")
        return None, None

def procesar_datos_geneticos(df, session_id):
    """Procesa los datos gen√©ticos y genera el informe.
    
    El proceso incluye:
    1. Extracci√≥n y validaci√≥n de SNPs
    2. Consulta a bases de datos gen√©ticas
    3. An√°lisis cl√≠nico de variantes
    4. Generaci√≥n del reporte final
    
    Args:
        df (pd.DataFrame): DataFrame con los datos gen√©ticos
        session_id (str): ID √∫nico de la sesi√≥n
        
    Returns:
        bool: True si el proceso fue exitoso, False en caso contrario
    """
    try:
        # Mostrar indicador de progreso
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # 1. Extraer y validar SNPs
        status_text.text("üîÑ Extrayendo y validando SNPs...")
        progress_bar.progress(0.2)
        
        # Validar formato de SNPs
        valid_snps = df[
            (df['rsid'].str.startswith('rs')) &
            (df['chromosome'].isin([str(i) for i in range(1, 23)] + ['X', 'Y', 'MT'])) &
            (df['position'].notna())
        ]
        
        if len(valid_snps) == 0:
            raise ValueError("No se encontraron SNPs v√°lidos en los datos")
        
        st.info(f"‚úÖ Se encontraron {len(valid_snps)} SNPs v√°lidos")
        
        # 2. Consultar bases de datos gen√©ticas
        status_text.text("üîÑ Consultando bases de datos gen√©ticas...")
        progress_bar.progress(0.4)
        
        # Inicializar gestor de base de datos
        db_manager = GenomicDatabaseManager()
        
        # Obtener lista de rs_ids
        rs_ids = valid_snps['rsid'].tolist()
        
        # Procesar datos usando el m√©todo que sabemos que funciona
        report_df = db_manager.procesar_datos_geneticos(rs_ids)
        
        if report_df is None or report_df.empty:
            raise ValueError("No se pudieron obtener datos de las bases de datos gen√©ticas")
        
        # 3. Generar informe detallado
        status_text.text("üîÑ Generando informe detallado...")
        progress_bar.progress(0.6)
        
        # Crear directorio de reports si no existe
        os.makedirs('reports', exist_ok=True)
        
        # Guardar el reporte en formato parquet
        report_path = f"reports/report_{session_id}.parquet"
        report_df.to_parquet(report_path)
        
        # Verificar que el archivo se cre√≥ correctamente
        if not os.path.exists(report_path):
            raise FileNotFoundError(f"No se pudo crear el archivo de reporte en {report_path}")
        
        st.info(f"Reporte guardado en: {report_path}")
        
        # 4. Generar informe narrativo
        status_text.text("üîÑ Generando informe narrativo...")
        progress_bar.progress(0.8)
        
        # Analizar hallazgos significativos
        significant_findings = report_df[
            (report_df['clinvar_clinical_significance'] != 'Unknown') |
            (report_df['gwas_p_value'] < 0.05)
        ]
        
        st.info(f"‚úÖ Se encontraron {len(significant_findings)} hallazgos significativos")
        
        # 5. Guardar resultados
        status_text.text("üîÑ Guardando resultados...")
        progress_bar.progress(1.0)
        
        # Mostrar enlace al informe
        st.success("‚úÖ Procesamiento completado")
        st.markdown(f"""
            ### üìä Informe Generado
            
            Tu informe detallado est√° listo. Puedes verlo haciendo clic en el siguiente enlace:
            
            [Ver Informe Detallado](/report?id={session_id})
            
            El informe contiene:
            - {len(valid_snps)} SNPs analizados
            - {len(report_df)} variantes encontradas
            - {len(significant_findings)} hallazgos significativos
            - Tabla interactiva con todos los resultados
            - Opci√≥n para descargar el informe completo
        """)
        
        return True
        
    except Exception as e:
        st.error(f"‚ùå Error durante el procesamiento: {str(e)}")
        logger.error(f"Error al procesar datos gen√©ticos: {str(e)}")
        return False

# =============================================================================
# Interfaz Principal
# =============================================================================

def main():
    """Funci√≥n principal de la aplicaci√≥n."""
    # Verificar estructura de directorios
    verificar_estructura_directorios()
    
    # Secci√≥n de subida de archivos
    st.header("üì§ Sube tus datos gen√©ticos")
    st.markdown("""
        Por favor, sube tu archivo de datos gen√©ticos de MyHeritage.
        El archivo debe estar en formato CSV con las columnas: RSID, CHROMOSOME, POSITION, RESULT
        
        ### Instrucciones:
        1. Descarga tu archivo de datos gen√©ticos de MyHeritage
        2. Aseg√∫rate de que el archivo tenga las columnas correctas
        3. Sube el archivo usando el bot√≥n de abajo
    """)
    
    archivo_subido = st.file_uploader(
        "Selecciona tu archivo MyHeritage",
        type=['csv', 'txt', 'tsv'],
        help="Archivo de datos gen√©ticos de MyHeritage (CSV o TSV)"
    )
    
    if archivo_subido is not None:
        try:
            # Mostrar informaci√≥n del archivo
            st.info(f"üìÑ Archivo subido: {archivo_subido.name}")
            
            # Leer el archivo CSV, ignorando las l√≠neas de comentario
            df = pd.read_csv(
                archivo_subido,
                comment='#',  # Ignorar l√≠neas que comienzan con #
                skip_blank_lines=True,
                dtype={
                    'RSID': str,
                    'CHROMOSOME': str,
                    'POSITION': int,
                    'RESULT': str
                }
            )
            
            # Mostrar informaci√≥n sobre las columnas encontradas
            st.info(f"Columnas encontradas en el archivo: {', '.join(df.columns)}")
            
            # Verificar y renombrar columnas si es necesario
            column_mapping = {
                'RSID': 'RSID',
                'CHROMOSOME': 'CHROMOSOME',
                'POSITION': 'POSITION',
                'RESULT': 'RESULT',
                'GENOTYPE': 'RESULT'  # Tambi√©n aceptar GENOTYPE como nombre alternativo
            }
            
            # Renombrar columnas si es necesario
            for old_col, new_col in column_mapping.items():
                if old_col in df.columns and old_col != new_col:
                    df = df.rename(columns={old_col: new_col})
                    st.info(f"Columna renombrada: {old_col} -> {new_col}")
            
            # Mostrar vista previa de los datos
            st.subheader("Vista previa de los datos")
            st.dataframe(df.head())
            
            # Validar los datos
            if validate_myheritage_data(df):
                # Convertir el archivo
                with st.spinner("üîÑ Convirtiendo archivo MyHeritage al formato requerido..."):
                    df_convertido, session_id = convert_myheritage(df)
                
                if df_convertido is not None:
                    # Mostrar vista previa de los datos convertidos
                    st.success("‚úÖ Archivo convertido correctamente")
                    st.subheader("Vista previa de los datos convertidos")
                    st.dataframe(df_convertido.head())
                    
                    # Procesar los datos y generar el informe
                    with st.spinner("üîÑ Procesando datos, espera por favor..."):
                        if procesar_datos_geneticos(df_convertido, session_id):
                            st.success("‚úÖ Procesamiento completado exitosamente")
                        else:
                            st.error("‚ùå Hubo un error al procesar tus datos. Por favor, intenta nuevamente.")
                else:
                    st.error("‚ùå No se pudo convertir el archivo. Por favor, verifica el formato y vuelve a intentarlo.")
            else:
                st.error("‚ùå El archivo no cumple con los requisitos de formato. Por favor, verifica las columnas y los datos.")
        
        except Exception as e:
            st.error(f"‚ùå Error: {str(e)}")
            st.error("Por favor, verifica que el archivo tenga el formato correcto y vuelve a intentarlo.")

# =============================================================================
# Ejecuci√≥n de la Aplicaci√≥n
# =============================================================================

if __name__ == "__main__":
    main()

optimizer = DatabaseOptimizer()
optimizer.create_indexes() 